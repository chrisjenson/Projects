CSC470-01 NLP
Project 2
Due: April 6, 2020 by 11:59PM
Title: N-Grams and Language Modeling
Description: In this project you will implement some of the language modeling techniques we discussed in class. 
You will gain hands-on experience with the training, i.e., probability estimation, phase and the testing, i.e., the model evaluation phase. 
In addition, you will gain experience implementing parameter estimation smoothing algorithms and using a LM (language model) to 
automatically generate language. You will also gain experience in corpus selection and analyze corpus impact on learned models. 
All corpora for this assignment must be in English.

Teams: Team Assignments will be emailed to students on March 23, 2020.

Tasks:
T1: Write a program to compute unsmoothed {uni,bi}-gram probability estimates using MLE (Maximum Likelihood Estimation).
T2: Add an option to probabilistically generate sentences using your probability estimates.
T3: Add an option to do add-1 smoothing.
T4: Add an option to compute the perplexity of a test set.
T5: Run your MLE training on two different corpora of your choice. 
There are many text corpora freely available on the web. See https://en.wikipedia.org/wiki/List_of_text_corpora for examples. 
You are also welcome to build/collect your own corpora. Compare the models learned from the different corpora. 
Write up an analysis of any interesting differences in the statistics learned and also interesting similarities. 
Give the top ten most probable {uni,bi}-grams and their probabilities. Cite other {uni,bi}-grams and their probabilities as 
you wish to aid in your exposition.
T6: Run your language generator using your two models. Give five or more sentences generated by your language generator and 
write up brief analysis.
T7: Repeat T5 and T6, but with Add-1 smoothing. Now also compare and contrast the Add-1 models with the MLE models.
T8: Compute and analyze the perplexity measured on held out test sets of data for each of your models and corpora.

Deliverables:
D1: Source code for training LMs using MLE and Add-1 smoothing and computing perplexity and probabilistically generating sentences. 
Can be written in computer programming language of choice, as long as it can run with the standard STEM 112 Mac lab configuration 
from terminal command-line prompt (same as for Project 1).
D2: Write-up with results and analysis from T5, T6, T7, and T8.Please submit as .tar.gz file.
